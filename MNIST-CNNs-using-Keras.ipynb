{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python",
      "language": "python",
      "name": "conda-env-python-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "DL0101EN-4-1-Convolutional-Neural-Networks-with-Keras-py-v1.0.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CdodtxH7Zzc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# **Convolutional Neural Networks with Keras**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgO_gNKV7Zzf",
        "colab_type": "text"
      },
      "source": [
        "We will learn how to use the Keras library to build convolutional neural networks. We will also use the popular MNIST dataset and we will compare our results to using a conventional neural network.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yyEK0Vj7Zzk",
        "colab_type": "text"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
        "\n",
        "<font size = 3>\n",
        "      \n",
        "1. <a href=\"#item41\">Import Keras and Packages</a>   \n",
        "2. <a href=\"#item42\">Convolutional Neural Network with One Convolutional and Pooling Layers</a>  \n",
        "3. <a href=\"#item43\">Convolutional Neural Network with Two Convolutional and Pooling Layers</a>  \n",
        "\n",
        "</font>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgCdJnF37Zzm",
        "colab_type": "text"
      },
      "source": [
        "<a id='item41'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LGderb77Zzp",
        "colab_type": "text"
      },
      "source": [
        "## Import Keras and Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3l_-GTC7Zzq",
        "colab_type": "text"
      },
      "source": [
        "Let's start by importing the keras libraries and the packages that we would need to build a neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNXjbzLY7Zzs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bff8a94a-1461-43a8-9151-86f5fd02f946"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reivDlrn7Z0F",
        "colab_type": "text"
      },
      "source": [
        "When working with convolutional neural networks in particular, we will need additional packages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yguLEUF7Z0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.convolutional import Conv2D # to add convolutional layers\n",
        "from keras.layers.convolutional import MaxPooling2D # to add pooling layers\n",
        "from keras.layers import Flatten # to flatten data for fully connected layers"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5sF5w-I7Z0V",
        "colab_type": "text"
      },
      "source": [
        "<a id='item42'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obSDr0Lt7Z0Z",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Layer with One set of convolutional and pooling layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H27iFfDb7Z0c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "005a6882-5256-4f8f-b976-20b78ab98b01"
      },
      "source": [
        "# import data\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# reshape to be [samples][pixels][width][height]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh9DZds07Z0r",
        "colab_type": "text"
      },
      "source": [
        "Let's normalize the pixel values to be between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6sJFO7M7Z0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train / 255 # normalize training data\n",
        "X_test = X_test / 255 # normalize test data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4kHEzrD7Z00",
        "colab_type": "text"
      },
      "source": [
        "Next, let's convert the target variable into binary categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR6OACfX7Z01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1] # number of categories"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrJg1Wls7Z09",
        "colab_type": "text"
      },
      "source": [
        "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBszNXC-7Z0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_model():\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), strides=(1, 1), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OhAcz297Z1H",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's call the function to create the model, and then let's train it and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WwiPuTx7Z1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "e64bcbaa-4be4-4fac-8c3e-3e29f6cac49c"
      },
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 8s - loss: 0.4593 - accuracy: 0.8699 - val_loss: 0.1309 - val_accuracy: 0.9648\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1151 - accuracy: 0.9663 - val_loss: 0.0815 - val_accuracy: 0.9751\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0808 - accuracy: 0.9762 - val_loss: 0.0657 - val_accuracy: 0.9789\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0645 - accuracy: 0.9807 - val_loss: 0.0539 - val_accuracy: 0.9824\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0537 - accuracy: 0.9841 - val_loss: 0.0443 - val_accuracy: 0.9858\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.0403 - val_accuracy: 0.9868\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0407 - accuracy: 0.9880 - val_loss: 0.0435 - val_accuracy: 0.9857\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0383 - accuracy: 0.9883 - val_loss: 0.0372 - val_accuracy: 0.9874\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0332 - accuracy: 0.9903 - val_loss: 0.0363 - val_accuracy: 0.9884\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0314 - accuracy: 0.9907 - val_loss: 0.0342 - val_accuracy: 0.9887\n",
            "Accuracy: 0.9886999726295471 \n",
            " Error: 1.130002737045288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-mfMjEM7Z1S",
        "colab_type": "text"
      },
      "source": [
        "------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAQLbq_b7Z1U",
        "colab_type": "text"
      },
      "source": [
        "<a id='item43'></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeVrQBBn7Z1V",
        "colab_type": "text"
      },
      "source": [
        "## Convolutional Layer with two sets of convolutional and pooling layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6v7t73m7Z1W",
        "colab_type": "text"
      },
      "source": [
        "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cXkF6rG7Z1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_model():\n",
        "    \n",
        "    # create model\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Conv2D(8, (2, 2), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    # Compile model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnRXZvmJ7Z1i",
        "colab_type": "text"
      },
      "source": [
        "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYn2Puis7Z1j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "179f9814-5c81-42b5-96f1-7485f2fac53a"
      },
      "source": [
        "# build the model\n",
        "model = convolutional_model()\n",
        "\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " - 3s - loss: 0.4829 - accuracy: 0.8623 - val_loss: 0.1273 - val_accuracy: 0.9618\n",
            "Epoch 2/10\n",
            " - 3s - loss: 0.1061 - accuracy: 0.9681 - val_loss: 0.0780 - val_accuracy: 0.9762\n",
            "Epoch 3/10\n",
            " - 3s - loss: 0.0769 - accuracy: 0.9766 - val_loss: 0.0611 - val_accuracy: 0.9809\n",
            "Epoch 4/10\n",
            " - 3s - loss: 0.0614 - accuracy: 0.9808 - val_loss: 0.0560 - val_accuracy: 0.9822\n",
            "Epoch 5/10\n",
            " - 3s - loss: 0.0519 - accuracy: 0.9842 - val_loss: 0.0456 - val_accuracy: 0.9863\n",
            "Epoch 6/10\n",
            " - 3s - loss: 0.0450 - accuracy: 0.9864 - val_loss: 0.0455 - val_accuracy: 0.9864\n",
            "Epoch 7/10\n",
            " - 3s - loss: 0.0395 - accuracy: 0.9883 - val_loss: 0.0450 - val_accuracy: 0.9855\n",
            "Epoch 8/10\n",
            " - 3s - loss: 0.0372 - accuracy: 0.9884 - val_loss: 0.0411 - val_accuracy: 0.9869\n",
            "Epoch 9/10\n",
            " - 3s - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0343 - val_accuracy: 0.9883\n",
            "Epoch 10/10\n",
            " - 3s - loss: 0.0296 - accuracy: 0.9906 - val_loss: 0.0376 - val_accuracy: 0.9870\n",
            "Accuracy: 0.9869999885559082 \n",
            " Error: 1.3000011444091797\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}